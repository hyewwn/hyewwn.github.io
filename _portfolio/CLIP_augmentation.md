---
layout: post
title: 'CLIP with text augmentation'
feature-img: 'assets/img/portfolio/blue.jpg'
img: 'assets/img/portfolio/clip.jpg'
date: 23 December 2023
tags: [CILP, ImageCaptioning, LLM]
---

## Introduction

This is project codes for the course of COSE474 at Korea University. This project was conducted as a personal project, and topics were freely selected from the fields of computer vision and deep learning.

The topic was "Better image captioning performance by using LLM" and I wanted to check how well data augmentation through Large Language Models improves image captioning performance.

## My Contribution

The motivation of this project stemmed from the versatility of LLMs in various NLP tasks. So, I divided image captioning model (CLIP) into image components and text components. To construct augmented data, I used Tk-INSTRUCT model, which is based on T5 and I tried to construct single-step training pipeline for data augmentation and fine-tuning of captioning model.

Link: [Click](https://github.com/hyewwn/COSE474)
