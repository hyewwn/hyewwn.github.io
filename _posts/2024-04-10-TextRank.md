---
layout: post
title: '[Paper Review] TextRank: Bringing Order into Texts' # Title of the page
hide_title: false # [Opt] Hide the title when displaying the post, but shown in lists of posts
#feature-img: "assets/img/sample.png"              # [Opt] Add a feature-image to the post
#thumbnail: "assets/img/thumbnails/sample-th.png"  # [Opt] Add a thumbnail image on blog view
#color: rgb(80,140,22)                             # [Opt] Add the specified colour as feature image, and change link colors in post
# position: 1 # [Opt] Set position on the menu navigation bar
tags: [NLP, Text Summarization, Graph] # [Opt] Add tags to the page
# author:
categories: NLP
---

본 포스팅에서 다룰 논문은 'TextRank: Bringing Order into Texts'입니다. 2004년 Proceedings of EMNLP로 발표된 논문으로 기존의 Web page ranking 알고리즘인 구글의 PageRank를 NLP 분야에 적용시켰습니다. 이를 통해 Text 내의 요소들(단어, 문장 등)을 중요도에 따라 Ranking을 매길 수 있도록 하고 있으며 이는 곧 Keyword Extraction, Text Summarization으로 대치됩니다. 

즉, 본 논문은 **Graph-based ranking model을 통한 비지도 텍스트 요약 알고리즘**을 제시하고 있습니다.

---

## Abstract

We introduce **TextRank** - a graph-based ranking model for text processing.

We propose two innovative **unsupervisd methods for keyword and sentence extraction**.

## Goals of the Paper

앞서 언급했듯이 본 논문의 목표는 Graph-based ranking model을 Text 도메인에 적용함으로써 비지도 방식으로 Keyword Extraction, Text Summarization을 수행하는 것이다.

따라서 본 논문은 Graph-based ranking model에 대한 설명과 이를 Word 단위, Sentence 단위에 대해 각각 적용하는 것으로 구성되어 있다.

--- 

### Graph-based ranking algorithm

본 논문에서 baseline으로 삼고 있는 모델은 1988년 구글에서 발표한 PageRank이다. PageRank는 World Wide Web의 연결 관계를 분석하기 위한 알고리즘으로 Web 상의 수많은 Page들을 Graph 구조로 본다.

Graph 구조는 Vertex와 Edge로 구성되며 방향성 및 가중치 여부에 따라 Directed/Undirected, Weighted/Unweighted Graph로 나누어진다.

<img src="/assets/img/pexels/graph.png" width="80%">

즉 PageRank에서는 각 Page를 Vertex로 Page 간의 연결 관계를 Edge로 표현한다.

이러한 Graph 구조에서의 Ranking algorithm은 Vertex의 중요도를 결정하는 것으로, 이때 일부 Local 영역에 대한 정보만을 반영하는 것이 아니라 회귀적으로 Convergence하도록 반복 학습함으로써 Global한 정보를 반영한다. 

또한, 여기서 Vertex의 중요도는 곧 해당 Vertex가 다른 Vertex와 얼마나 많이, 강하게 연결되어 있는가에 비례한다. 

본 논문에서 제시하고 있는 TextRank는 각 단어 또는 각 문장을 Vertex로, Text에서 추출할 수 있는 연결관계를 Edge로 표현하여 graph-based ranking algorithm을 적용하고 있으며 그 결과로 Keywords 또는 Summarization sentences가 Top N의 방식으로 결정될 수 있도록 한다.

### The TextRank Model

#### Directed Graphs

Directed graph는 $$G = (V,E)$$로 나타낼 수 있으며 여기서 $$V$$는 vertex 집합을 $$E$$는 edge 집합을 의미한다. 또한 Directed graph의 경우 방향성이 존재하기 때문에 $$In(V_i)$$를 **vertex $$i$$를 가리키는** vertex 집합으로 $$Out(V_i)$$를 **vertex $$i$$가 가리키는** vertex 집합으로 표기할 수 있다.

이때 vertex $$V_i$$의 importance score는 다음과 같은 수식으로 정의될 수 있다.

<img src="/assets/img/pexels/graph_impscore.png" width="70%">

위 수식은 "Random sufer model"로 불리며 user가 어떤 링크를 클릭할 확률을 $$d$$로, 해당 링크에서 새로운 페이지로 이동할 확률을 $$1-d$$로 나타낸다. ($$d$$는 damping factor로 0~1 사이의 수) 

즉, 위 수식은 그래프에서 한 vertex에서 다른 vertex로 jump할 확률을 나타내며, 연결관계가 많을수록 높은 점수로 나타난다. 

위 Score는 초기값의 영향을 받지 않으며 충분한 iteration을 통해 일정 값으로 수렴한다.

#### Undirected Graphs

Undirected graph의 경우 Directed Graph와 거의 유사하나 vertex의 in-degree와 out-degree가 동일한 경우로 이해할 수 있다.

따라서 앞선 Directed Graph에서의 수식을 그대로 사용할 수 있으며, Convergence curve를 그려보았을 때 거의 유사하게 오버랩되는 것을 확인할 수 있다.

#### Weighted Graphs

기존의 PageRank 모델은 각 페이지들이 여러 개(multiple)의 link로 연결되거나 부분적인(partial) link로 연결되는 등의 경우가 없다. 그러나 본 논문에서 다루고자 하는 Text의 경우 추출된 unit(vertex)들이 multiple 또는 partial link를 가질 수 있다. 

또한 이러한 특성은 연결의 strength로 표현할 수 있으며 edge의 weight로 나타낼 수 있다.

따라서 vertex $$V_i$$와 $$V_j$$ 사이 edge의 weight를 $$w_{ij}$$로 표현한다.

이렇게 weight를 반영하여 각 vertex의 score를 결정하는 수식은 아래와 같다.

<img src="/assets/img/pexels/graph_impscore_weight.png" width="70%">

위 수식을 사용했을 경우에도 Convergence curve가 유사하게 나타났다.

#### Text as a Graph

본 논문에서는 Graph 기반 Ranking 알고리즘을 Text에 적용하고 있기 때문에 Text를 효과적으로 Graph 구조로 변형시켜 주는 것이 매우 중요하다. 특히 각 text entity 간의 의미적 관계가 기반이 되어야 한다. 이때 Text unit의 크기는 다양하게 구성될 수 있다. (word, collocations, entire sentence 등)

또한, Entity 간의 관계 역시 어휘적(Lexical), 의미적(Semantic) 관계, 맥락적 오버랩(Contextual overlap) 등 다양하게 연결될 수 있다.

> **Text가 Graph로 변환되는 과정은 다음과 같다.**   
1. Task에 적합한 Text unit을 추출하여 graph의 vertex에 넣어준다. 
2. 추출된 Text unit간의 관계를 결정하고 이를 edge로 연결한다. 이때 edge는 directed/undirected, weighted/unweighted 모두 가능하다. 
3. Graph-based ranking algorithm을 수렴할 때까지 (convergence threshold를 기준으로) 반복한다.
4. Vertices를 최종 score 기준으로 내림차순 정렬하고 task에 따라 ranking/selection을 수행한다.

본 논문에서는 Keyword Extraction과 Text Summarization Task를 다루고 있으며 이 두 Task는 각각 text unit으로 word, entire sentence를 사용한다.


### Keyword Extraction

Keyword Extraction task에서는 각 단어를 vertex로 놓는다. Vertex로 들어가는 단어는 task에 따라 Syntactic filter를 적용하여 명사만, 명사와 동사만, 명사와 형용사만 등 옵션을 다르게 설정할 수 있다.

또한, vertex를 연결하는 edge를 결정하는 기준을 설정해야 하는데 이는 *co-occurrence*를 기준으로 한다.

즉, 두 vertices가 $$N$$ word window 안에 같이 나타난다면 이를 *co-occurr* 하였다고 말하며 edge로 연결한다. 이때 $$N$$은 2~10 사이의 수로 정할 수 있다.

Graph를 구성하고 난 뒤에는 Ranking 알고리즘을 반복 수행하여 각 vertex의 score를 수렴시킨다. 최종 score가 결정되면 Top $$T$$개를 선택함으로써 Keyword Extraction이 가능하다.

이때, 일부 단어는 2단어 이상으로 구성될 수 있다. (Ex. New York) 이런 경우 Post-processing 과정을 통해 Top $$T$$ 속의 단어들이 텍스트 속에서 바로 인접하여 나타난다면 하나의 multi-word keyword로 합칠 수 있다. (Ex. New, York: *New York* city is center of America.)

저자들의 실험 결과 F-measure를 기준으로 TextRank가 기존에 제안되었던 모델들보다 더 높은 스코어를 기록하였다고 한다.

### Sentence Extraction

Sentence Extraction에서는 각 문장을 vertex로 놓는다. 그러나 문장은 반복적으로 나타나지 않기 때문에 Keyword extraction과는 다른 방식으로 edge를 구성하여야 한다.

따라서 *co-occurrence*를 이용하는 것 대신에 두 문장 간의 *similarity*를 이용하며, similarity를 결정하는 기준은 문장 간의 overlap, string kernels, cosine similarity, longest common subsequence 등을 모두 사용할 수 있다.

본 논문에서는 공통된 token이 얼마나 overlap 되는 지를 기준으로 하고 있다. 이때도 syntatic filter를 사용함으로써 token을 필터링할 수 있다.

또한, 문장이 길어짐으로써 overlap이 과도하게 일어날 수 있기 때문에 이를 normalization factor를 이용해 조절하고 있다.

위 사항들을 반영한 similarity 계산 수식은 아래와 같다.

<img src="/assets/img/pexels/graph_simscore.png" width="70%">

이처럼 sentence extraction task에서는 각 edge가 similarity score로 나타나기 때문에 weighted graph가 구성된다. 

$$ROUGE$$ evaluation toolkit을 이용해 human evaluation과 비교한 결과 TextRank가 기존의 지도학습 기반의 방식들과 유사한 성능을 보이고 있음을 확인하였다.

유사한 성능을 가진 다른 모델들과 달리 TextRank는 비지도학습 기반이기에 데이터에 대한 제약이 적다는 장점을 갖는다.

---

> Keyword extraction, Sentence extraction task에서 비지도학습 방식을 성공적으로 적용시켰다는 점에서 의의가 있는 것 같습니다. 특히 NLP에 Graph를 적용하는 방식이 Knowledge를 이용하는 등의 방식이 아니라 Text를 일정 기준에 따라 그대로 Graph로 변환시킨다는 점이 인상깊습니다.
